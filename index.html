<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Jon Barron and Deepak Pathak and Abhishek Kar and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 400
  }
  heading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 17px; /* 19 */
    font-weight: 600 /* 1000 */
  }
  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
  strong {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 600 /* 800 */
  }
  strongred {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    font-weight: 600
  }
  pageheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 38px;
    font-weight: 400
  }
  .ImageBorder
  {
      border-width: 1px;
      border-color: Black;
  }
  
  /* 论文区的 bibtex 代码块 *//* 仅作用于论文区的 bibtex 代码块 */
  .paper pre {
    display: none;              /* 初始隐藏，配合你的 toggle 使用 */
    max-width: 100%;            /* 不允许超过单元格宽度 */
    overflow-x: auto;           /* 太长时出横向滚动条，而不是撑开布局 */
    white-space: pre-wrap;      /* 允许按空白换行 */
    word-break: break-word;     /* 必要时断长单词 */
    box-sizing: border-box;

    /* 下面是观感优化，可要可不要 */
    background: #f7f7f7;
    border-radius: 8px;
    padding: 10px 12px;
    margin: 8px 0 0;
    font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", monospace;
    font-size: 13px;
    line-height: 1.4;
  }

  </style>
  <!-- <link rel="shortcut icon" href="images/apple-touch-ri-logo-white-120x120.png"> -->
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Huang Yinming</title>
  <meta name="Yinming Huang's Homepage" http-equiv="Content-Type" content="Yinming Huang's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <!-- Start : Google Analytics Code -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-XXXXX-Y', 'auto');
    ga('send', 'pageview');
    </script>
  <!-- End : Google Analytics Code -->
  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>


</head>
 
<body>
<table width="900" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center">
    <pageheading>Yinming Huang 「黄音铭」</pageheading><br>
  </p>

  <tr>
    <td width="30%" valign="top"><a href="images/yinminghuang_Cal.jpg"><img src="images/yinminghuang_Cal.jpg" width="100%" style="border-radius:15px"></a>
    <p align=center>
    | <a href="https://github.com/YinmingHuang">Github</a> |
    <a href="mailto:22307140123@m.fudan.edu.cn">Email</a> |
    <!-- <a href="https://scholar.google.com/citations?user=TVWH2U8AAAAJ">Google Scholar</a> |
    <br/>
    | <a href="https://github.com/TairanHe">Github</a> | 
    <a href="https://www.linkedin.com/in/tairan-he-41a904294/">LinkedIn</a> |
    <a href="https://space.bilibili.com/14145636">Bilibili</a> |  -->
    <!-- </p>
    <p align="center" style="margin-top:-8px;"><iframe id="twitter-widget-0" scrolling="no" frameborder="0" allowtransparency="true" allowfullscreen="true" class="twitter-follow-button twitter-follow-button-rendered" style="position: static; visibility: visible; width: 156px; height: 20px;" title="Twitter Follow Button" src="https://platform.twitter.com/widgets/follow_button.2f70fb173b9000da126c79afe2098f02.en.html#dnt=false&amp;id=twitter-widget-0&amp;lang=en&amp;screen_name=TairanHe99&amp;show_count=false&amp;show_screen_name=true&amp;size=m&amp;time=1706734206165" data-screen-name=""></iframe><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p> -->
    </td>
    <td width="70%" valign="top" align="justify">
      <p>I am a third-year undergraduate student at <a href="https://www.fudan.edu.cn/">Fudan University</a>. I am currently a research intern in <a href="https://fvl.fudan.edu.cn/">Fudan Vision and Learning Laboratory</a> advised by <a href="https://zxwu.azurewebsites.net/"> Zuxuan Wu</a>. My research interests lie in Computer Vision and AI-Generated Content (AIGC).
      </p>
      <!-- <p>Goal: challenge conventional notions of what robots can achieve, develop robots that improves everyone's life. Focus: developing intelligent robots being able to do useful tasks with <u>intelligence, generalizability, agility and safety</u>. Method: learning-based methods that scale with the computation and data. Robots: Mobile robots, legged robots, robotic manipulators, and humanoid robots.
      </p> -->
      <!-- <p><strong>Goal:</strong> Robots that improve everyone's life.</p>
      <p><strong>Focus:</strong> How to build the <u>data flywheel for robotics</u> to unlock human-level athletic skills and semantic intelligence? How to make robots perform useful tasks with <u>adaptability, generalizability, agility, and safety</u>?</p>
      <p><strong>Method:</strong> Utilizing learning-based methods that scale with computation and data.</p>
      <p><strong>Robots:</strong> I love working on humanoids and aim to make them capable of doing everything I can do—and more.</p> -->
      <p>Email: 22307140123 [AT] m.fudan.edu.cn
      </p>
    </td>
  </tr>
</table>


<hr/>
<!-- ===================== Education, Awards, Experience Section ===================== -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr valign="top">
    <!-- ========== Left Column ========== -->
    <td width="50%">
      <sectionheading>Education</sectionheading>
      <p>
        <strong>Fudan University</strong><br/>
        B.Eng. in Artificial Intelligence<br/>
        <em>Sep. 2022 – Present</em>
      </p>
      <p>
        <strong>No. 2 High School Attached to East China Normal University</strong><br/>
        High School Diploma<br/>
        <em>Aug. 2019 – Jul. 2022</em>
      </p>

      <sectionheading>Honors & Awards</sectionheading>
      <ul>
        <li>First-Class Scholarship for Outstanding Undergraduate Students, Fudan University (Sponsored by BYD), 2023-2024</li>
        <li>First-Class Scholarship for Outstanding Undergraduate Students, Fudan University (Sponsored by Huawei), 2022-2023</li>
        <li>First Prize in the Preliminary Round of the Chinese Mathematical Olympiad (2021)</li>
      </ul>
    </td>

    <!-- ========== Right Column ========== -->
    <td width="50%">
      <sectionheading>Experience</sectionheading>
      <p>
        <strong>University of California, San Diego</strong><br/>
        Exchange Student<br/>
        <em>Sep. 2024 – Dec. 2024</em>
      </p>
    </td>
  </tr>
</table>

<hr/>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Publications</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">


  <tr>
    <td width="40%" valign="top" align="center">
      <a href="https://francis-rings.github.io/StableAvatar/">
          <img src="images/stableavatar/framework_00.png" alt="sym" width="90%" style="padding-top:0px; padding-bottom:0px; border-radius:15px; height: auto;">
      </a>
    </td>
    <td width="60%" valign="top">
      <p><a href="https://francis-rings.github.io/StableAvatar/" id="STABLEAVATAR">
      <heading>StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation</heading></a><br>
      Shuyuan Tu, Yueming Pan, <strong>Yinming Huang</strong>, Xintong Han, Zhen Xing, Qi Dai, Chong Luo, Zuxuan Wu, Yu-Gang Jiang<br>
      </p>

      <div class="paper" id="stableavatar">
      <a href="https://francis-rings.github.io/StableAvatar/">webpage</a> |
      <a href="javascript:toggleblock('stableavatar_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('stableavatar')" class="togglebib">bibtex</a> |
      <a href="https://arxiv.org/abs/2508.08248">arXiv</a> |
      <a href="https://github.com/Francis-Rings/StableAvatar">code</a> |
      <a href="https://www.youtube.com/watch?v=6lhvmbzvv3Y">video</a>
      

      <p align="justify" id="stableavatar_abs" style="display: none;"> <i>Current diffusion models for audio-driven avatar video generation struggle to synthesize long videos with natural audio synchronization and identity consistency. This paper presents StableAvatar, the first end-to-end video diffusion transformer that synthesizes infinite-length high-quality videos without post-processing. Conditioned on a reference image and audio, StableAvatar integrates tailored training and inference modules to enable infinite-length video generation. We observe that the main reason preventing existing models from generating long videos lies in their audio modeling. They typically rely on third-party off-the-shelf extractors to obtain audio embeddings, which are then directly injected into the diffusion model via cross-attention. Since current diffusion backbones lack any audio-related priors, this approach causes severe latent distribution error accumulation across video clips, leading the latent distribution of subsequent segments to drift away from the optimal distribution gradually. To address this, StableAvatar introduces a novel Time-step-aware Audio Adapter that prevents error accumulation via time-step-aware modulation. During inference, we propose a novel Audio Native Guidance Mechanism to further enhance the audio synchronization by leveraging the diffusion's own evolving joint audio-latent prediction as a dynamic guidance signal. To enhance the smoothness of the infinite-length videos, we introduce a Dynamic Weighted Sliding-window Strategy that fuses latent over time. Experiments on benchmarks show the effectiveness of StableAvatar both qualitatively and quantitatively.</i></p>

<pre xml:space="preserve" style="display: none;">
  @article{tu2025stableavatar,
    title={StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation},
    author={Tu, Shuyuan and Pan, Yueming and Huang, Yinming and Han, Xintong and Xing, Zhen and Dai, Qi and Luo, Chong and Wu, Zuxuan and Jiang Yu-Gang},
    journal={arXiv preprint arXiv:2508.08248},
    year={2025}
  }
</pre>
      </div>
    </td>
  </tr>



<table width="100%" align="center" border="0" cellspacing="0" cellpadding="2">
    <tr><td><br><p align="right">
    Website template from <a href="https://tairanhe.com/">here</a> and <a href="https://github.com/luost26/academic-homepage">here</a> 
    </font></p></td></tr>
</table>

  </td></tr>
</table>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
</body>

</html>
